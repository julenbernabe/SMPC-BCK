import random

n=150


#Tal y como tenemos el programa guardamos todos estos datos en una matriz
#de tal manera que las 2 primeras columnas seran edad y salario y la ultima columna corresponde a la Yellow
training_data=sfix.Matrix(2*n,3)

# Rellenar con los datos del player0
@for_range(n)
def setTrainin_data(i):
  training_data[i][0] = sfix.load_sint(sint.get_private_input_from(1))

@for_range(n,2*n)
def setTrainin_data(i):
  training_data[i-n][1] = sfix.load_sint(sint.get_private_input_from(1))

@for_range(2*n,3*n)
def setTrainin_data(i):
  training_data[i-2*n][2] = sfix.load_sint(sint.get_private_input_from(1))


# Rellenar con los datos del player1
@for_range(n)
def setTrainin_data(i):
  training_data[i+n][0] = sfix.load_sint(sint.get_private_input_from(2))

@for_range(n,2*n)
def setTrainin_data(i):
  training_data[i][1] = sfix.load_sint(sint.get_private_input_from(2))

@for_range(2*n,3*n)
def setTrainin_data(i):
  training_data[i-n][2] = sfix.load_sint(sint.get_private_input_from(2))


#  2- VALORES_Y 
#Esto no tiene por que ser secreto y facilita muchos las cosas
valores_y=sfix.Array(2)
valores_y[0]=sfix(0)
valores_y[1]=sfix(1)


#  3- NUMERIC_LIST 
numeric_list=sfix.Array(3)
numeric_list[0]=sfix(1)
numeric_list[1]=sfix(1)
numeric_list[2]=sfix(0)



#-----------------------------------------------------------------------------------------
#                                       FUNCIONES
#-----------------------------------------------------------------------------------------

#-------------------------------- FUNCION element_search ---------------------------------
#Funcion para buscar si un elemento a esta en un Array lista

def element_search(a,lista):
    n=len(lista)
    result=MemValue(sint(0))
    #Aqui guardamos si son iguales o no:
    equal=sfix.Array(1)
    equal[0]=sfix(0)

    @for_range(n)
    def range_body(i):
        result.write(result+(lista[i] == a))

    @if_e((result.read()==0).reveal())
    def block():
        equal[0] = sfix(0)
    @else_
    def block():
        equal[0] = sfix(1)
    
    return equal[0]


#------------------------------------- FUNCION question -------------------------------------
#Es una lista con dos atributos:
#   columna: columna de donde se saca la pregunta
#   valor: el valor que toma en dicha columna

#Es decir, para hacer las preguntas:
#   Es edad >=15? Se hace question (0,15)
#                    edad es la columna 0

def question(columna,valor):
    pregunta=sfix.Array(2)
    pregunta[0]=columna
    pregunta[1]=sfix(valor)
    return pregunta

#---------------------------------- FUNCION match_question -----------------------------------
#Se le da una pregunta y una fila como argumento
#El resultado es si esa fila responde a la pregunta o no
#Tambien hay que darle como argumento numeric_list para que sepa si es una pregunta sobre una
#variable cuantitativa o sobre una cualitatita.


def match_question(question,row,numeric_list):

    #Primero comparamos si la pregunta la hacemos sobre una variable categorica o numerica
    #question[0] guarda la columna, es decir, la variable 

    variable=question[0]
    #numeric=numeric_list[variable] #El problema es que para esto variable tiene que ser un entero
    #valor=row[variable]

    numeric=sfix.Array(1)
    numeric[0]=sfix(0)

    valor=sfix.Array(1)
    valor[0]=sfix(0)

    @for_range(len(numeric_list))
    def range_body(i):
        @if_e((variable==i).reveal()==1)
        def block():
            numeric[0]=numeric_list[i]
            valor[0]=row[i]
        @else_
        def block():
            numeric[0]=numeric[0]
            valor[0]=valor[0]
            

    

    result=sfix.Array(1)
    result[0]=sfix(0)

    @if_e((numeric[0]==1).reveal()==1)
    def block():
        @if_e((valor[0] >= question[1]).reveal()==1)
        def block():
            result[0]=sfix(1)
        @else_
        def block():
            result[0]=sfix(0)
    @else_
    def block():
        @if_e((valor[0] == question[1]).reveal()==1)
        def block():
            result[0]=sfix(1)
        @else_
        def block():
            result[0]=sfix(0)

    return result[0]



#----------------------------------------- FUNCION gini ------------------------------------------
#Sirve para calcular la impureza de gini
#Como de frecuente es que un elemento elegido de forma random sea clasificado incorrectamente
    #si se elige el tipo de forma random, es decir, si tienes un bol con naranjas, mandarinas y manzanas
    #y otro bol con papeles en los que pone naranja, mandarina o manzana
    #Se elige de cada bol un elemento de forma random.
    #La frecuencia de que no coincida se mide con la impureza de gini.
#formula sacada de : https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity

#En realidad, no tendremos una lista con el data dividido, por lo que hay la funcion de gini toma el data entero 
#y la lista partition_list que le indica como esta dividido para dividirlo dentro de la funcion 

def gini(data,valores_y,partition_list,nodo):
    
    #Numero de categorias de la variable y
    #pero puede que las m no esten en el subdata que estamos mirando
    m=len(valores_y) 

    #En counts lo que tenemos que guardar es por cada tipo diferente de ultima variable cuantos hay
    #En caso de que ese variable no este en nuestro conjunto sera cero 
    #Si es cero no influye porque p_i sera 0 y no se le resta nada a gini
    counts=sfix.Array(m) 
    
    #Guadamos en una variable el numero de elementos de ese nodo:
    q=sfix.Array(1)
    q[0]=sfix(0)

    #Miramos de entre todas las filas del data las que estan en nuestro nodo
    @for_range(len(data))
    def range_body(i):
        #Miramos los que en la partition_list tengan justo ese numero de nodo
        @if_e((partition_list[i]==nodo).reveal()==1)
        def block():
            #Sumamos uno al numero de elementos de ese nodo:
            q[0]=q[0]+1
            #Cogemos el valor que toma esta fila en la variable Y
            label=data[i][-1]

            #Ahora miramos cual de todas las m posibilidades de Y es y le sumamos uno:
            @for_range(m)
            def range_body(j):
                categoria=valores_y[j]

                #Si el valor de label es igual al de la categoria sumamos counts[j]+1
                @if_e((label==categoria).reveal()==1)
                def block():
                    counts[j]=counts[j]+1
                @else_
                def block():
                    counts[j]=counts[j]
        @else_
        def block():
            nada=0
            #no hacemos nada
 
    
    #La formula es:
    #I=1- sum(i=1,2,...,m)p_i^2
    #suponiendo que m es el numero de clases y p_i la fraccion de items clasificados como clase i
    
    impurity=sfix.Array(1)
    impurity[0]=sfix(1)

    @for_range(m)
    def range_body(i):
        p_i = counts[i] / q[0]
        impurity[0] =impurity[0] - p_i*p_i

    return impurity[0]


#-----------------------------PARA REALIZAR 2^EXPONENTE---------------------------------
from Compiler import mpc_math

sfloat.vlen = 15 # Length of mantissa in bits
sfloat.plen = 10 # Length of exponent in bits
sfloat.kappa = 4 # Statistical security parameter for floats



#-------------------------------------- FUNCION info_gain -----------------------------------------
# La uncertainity del nodo de entrada(es decir el indice de gini) menos las impurezas ponderaas de los dos hijos
# En este caso nodo es el nodo anterior a relizar la partition list
# Es decir partition list es la de los nodos hijos, peor nodo es el nodo madre, que ya no estara en partition_list

def info_gain(data,valores_y,partition_list, current_uncertainty,nodo,iteration,p):
    exp2_iter=mpc_math.exp2_fx(iteration)

    #SACAR EL NUMERO QUE CORRESPONDE A LOS DE FALSE DEPENDIENDO DE LA ITERACION Y DE LA RAMA:
    es_false=nodo + exp2_iter + p

    #SACAR EL NUMERO QUE CORRESPONDE A LOS DE TRUE DEPENDIENDO DE LA ITERACION Y DE LA RAMA:
    es_true=nodo + exp2_iter + p + sfix(1)

    trues=MemFix(sfix(0))

    falses=MemFix(sfix(0))

    @for_range(len(partition_list))
    def range_body(i): 
        @if_e((partition_list[i]==es_true).reveal()==1)
        def block():
            trues.iadd(1)
        @else_
        def block():
            trues.iadd(0)
        
        @if_e((partition_list[i]==es_false).reveal()==1)
        def block():
            falses.iadd(1)
        @else_
        def block():
            falses.iadd(0)

    prob = trues.read() / (trues.read()+falses.read())

    
    resultado = current_uncertainty - prob * gini(data,valores_y,partition_list,es_true) - (1 - prob) * gini(data,valores_y,partition_list,es_false)
    
    return resultado



#-------------------------------------- FUNCION partition -----------------------------------------
#Se encarga de partir el dataset en dos datasets dependiendo de la respuesta a la pregunta
#Para cada linea de un dataset, comprobar si la respuesta a la pregunta es verdadero o falso 
#   Si es verdadero se agrega la linea a true_rows
#   Si es falsa se agrega la linea a false_rows

#No devuelve una lista para true y otra para false, devuelve una unica lista que se va actualizando
#donde se indica cada fila a que nodo pertenece

# Dependiendo de la iteration  y el nodo haremos que ponga unos numeros o otros

def partition(data, partition_list,question,numeric_list,nodo,iteration,p):

    partition_nueva=sfix.Array(len(data))

    exp2_iter=mpc_math.exp2_fx(iteration)

    #SACAR EL NUMERO QUE CORRESPONDE A LOS DE FALSE DEPENDIENDO DE LA ITERACION Y DE LA RAMA:
    nodo_false=nodo + exp2_iter + p

    #SACAR EL NUMERO QUE CORRESPONDE A LOS DE TRUE DEPENDIENDO DE LA ITERACION Y DE LA RAMA:
    nodo_true=nodo + exp2_iter + p + sfix(1)
    

    @for_range(len(data))
    def range_body(i): 
        #Comprobamos si esa fila pertenece al nodo que queremos dividir
        @if_e((partition_list[i]==nodo).reveal())
        def block():
            #Si pertenece al nodo cogemos la linea y le hacemos la pregunta
            row=data[i]
       
            @if_e((match_question(question,row,numeric_list)).reveal()==1)
            def block():
                partition_nueva[i]=nodo_true

            @else_
            def block():
                partition_nueva[i]=nodo_false

        #Si no pertenece al nodo que queremos dividir se queda igual
        @else_
        def block():
            partition_nueva[i]=partition_list[i]

 
    return partition_nueva

#--------------------------------- FUNCION best_split_gini_random ----------------------------------------

#Meterle n_variablesX a mano para que sea un entero y no un sfix

#Funcion para encontrar el mejor corte basandose en la impureza de gini
#Encontrar la mejor pregunta que hacer eligiendo de forma random las variables que vamos a mirar
#Este mecanisimo se utiliza para controlar el overfitting. Es similar a la tecnica de random forest. 
#La diferencia es que en el Random Forest se separa de forma random tambien el data y se hacen varios arboles 
#Aunque fijemos el numero de variables a 3, segun se vaya a lo largo del arbol acabaran apareciendo todas las variables 

#Tambien voy a fijar el numero de valores que se fijan en cada variable (esto creo que no lo hace scikit-learn), 
#pero hace que el proceso sea mucho mas rapido y actua de forma similar. 
#Esto solo para las variables cuantitativas

#Para las variables cualitativas se mira cada categoria en una lista que le pasamos

#Por lo tanto los parametros nuevos que metemos son:
#   - max_features (el maximo numero de variables que miramos cada vez que dividimo un nodo)
#   - max_values (el maximo numero de valores de cada variable cuantitativa que miramos en cada division)
#   - valores_color (las distintas categorias de la variable categorica color)
#   - valores_... (en caso de que hubiese mas variables categoricas tambien hay que meterals como parametro)
#                  ESTO ESTA UN POCO MAL ASI, PENSAR OTRA FORMA DE PONERLO 

def best_split_gini_random(data,valores_y,partition_list,nodo,numeric_list,iteration,p,max_features,max_values,n_variablesX):
    
    # aqui guardamos la mayor ganancia de infomracion
    best_gain = sfix.Array(1)  
    #Lo inicializamos en 0
    best_gain[0]=sfix(0)

    # aqui guardamos el valor y la columna que hacen la mejor pregunta
    best_question=sfix.Array(2)
    best_question[0]=sfix(0)
    best_question[1]=sfix(0)
    #Por el momento lo inicializamos en [0,0], aunque eso es una pregunta de por si.
    #(no influye, si es la mejor esta bien y si no lo es se reemplazara)

    start_timer(2)      
    current_uncertainty = gini(data,valores_y,partition_list,nodo)
    stop_timer(2)

    #Con max_features tenemos el numero de variables que mirar en cada iteracion.
    #Ahora se elige de forma random cuales van a ser esas dos variables

    #Del 0 a n_variablesX elegimos max_features numeros de forma random y los guardamos en una lista.
    #Para que funcione random vamos a tener que guardarlos en una lista de PYTHON
    random.seed(0)
    variables_division = [random.randint(0,n_variablesX-1) for i in range(max_features)]

    #Definimos un Array para guardar la nueva partition:
    partition_nueva=sfix.Array(len(data))

    
    
    for i in range(max_features):
        col=variables_division[i]
        print_ln('una de las variables elegidas es: %s',col)
        #Para cada variable explicativa x que se elige de forma random 

        # OPCIONES:
        # 1- Vamos mirando uno a uno cada una de estas filas y debemos comprobar que realmente esten en nuestro nodo
        #Osea que en realidad se miraran incluso menos valores que max_values (porque muchos no estaran en el nodo)
        #No se si es buena idea hacerlo asi, se van a mirar muy pocos valores al final !
        #   Si ponemos un valor muy grande de max_values en la primera iteracion se miraran muchos
        #   pero en las siguientes opraciones pocos
        #   Si ponemos un valor muy peque de max_values en las primeras iteraciones bien, pero en las siguientes apenas 
        #   se miraran valores  

        # 2- Otra forma, dejarlo igual pero elegir de forma random cada valor con 0 o 1 si lo elegimos
        #Ir contando con cuantos nos sale un uno y parar cuando llegamos a max_values
        #Lo malo es que probablemente acabe elgiendo los primeros mas si hay muchos datos y no llegaria hasta los ultimos
        #Otra opcion es elegir de forma random por que indice empezar a mirar y despues hacer eso.
        #ESTO ULTIMO TAMPOCO ES MALA OPCION

        
        # 3- Ir mirando en orden todas las lineas e ir sumando cuantos metemos hasta max_values
        #pero entonces no es random! siempre se mirarian los primeros!!!!!

        # 4- Poner un valor random grande y hacer un while hasta que se acabe la lista o hasta que sea al menos max_values
        
        # 5- DEFINITIVA POR EL MOMENTO Reasignar a cada fila un valor random y hacer un if de que la cuenta de los que se van mirando sea menor que  max_values

        #Elegimos len(data)[Es por asegurarnos de poner un valor grande] indices random donde estaran los valores que van de 0 a numero de lineas del dataset
        random.seed(0)
        n=len(data)
        valores_variables = [random.randint(0,n-1) for j in range(n)]

        #Lo malo es que algunos pueden estar repetidos 

        #Vamos contando el numero de valores que elegimos
        no_values=MemFix(sfix(0))

        for j in range(len(data)):
            #miramos solo hasta max_values valores random dentro de los que toma esa variable 
            @if_e((no_values.read()<max_values).reveal())
            def block(): 
                print_ln('Todavia no he llegado al maximo numero de valores (esto saldra 10 veces)')

                indice_random=valores_variables[j]
                print_ln('El indice random es: %s',indice_random)

                #Miramos los que en la partition list tengan justo ese numero de nodo
                #Es decir,los que realmente pertenecen al data del nodo que queremos dividir        
                @if_e((partition_list[indice_random]==nodo).reveal())
                def block():
                    no_values.iadd(1)
                    print_ln('Este indice esta en el nodo que queremos dividir')

                    valor=data[indice_random][col] #ESTO CAMBIAAAAAAAAAAAAAAAAAAAAAA
                    #para cada valor que puede tomar se realiza la pregunta
                    pregunta = question(col, valor)

                    # Intentar dividir el dataset mediante esa pregunta
                    '''
                    start_timer(3) 
                    partition_nueva = partition(data, partition_list,pregunta,numeric_list,nodo,iteration,p)
                    stop_timer(3)
                    
                    exp2_iter=mpc_math.exp2_fx(iteration)

                    #SACAR EL NUMERO QUE CORRESPONDE A LOS DE FALSE DEPENDIENDO DE LA ITERACION Y DE LA RAMA:
                    es_false=nodo + exp2_iter + p

                    #SACAR EL NUMERO QUE CORRESPONDE A LOS DE TRUE DEPENDIENDO DE LA ITERACION Y DE LA RAMA:
                    es_true=nodo + exp2_iter + p + sfix(1)

                    # Si el corte no divide el dataset saltarselo. Para ello, miramos que los numeros
                    # esten al menos una vez en partition_list. Si lo divide estaran los dos numeros,
                    # por lo que con mirar que esta uno de los dos vale, miramos por ejemplo que este es_false
          
                    @if_e((element_search(es_false,partition_nueva)==0).reveal())
                    def block():
                        #Si no esta es porque no lo ha dividio, no actualizamos
                        best_gain[0]=best_gain[0]
                    @else_
                    def block():    
                        # Calcular la ganancia de informacion con ese corte
                        start_timer(4)
                        gain = info_gain(data,valores_y,partition_nueva, current_uncertainty,nodo,iteration,p)
                        stop_timer(4)
                                     

                        @if_e((gain>=best_gain[0]).reveal()==1)
                        def block():
                            best_gain[0]=gain
                            best_question[0]=pregunta[0]
                            best_question[1]=pregunta[1]
                        @else_
                        def block():
                            best_gain[0]=best_gain[0]
                    '''
                @else_
                def block():
                    print_ln('Este indice no esta en el nodo que queremos dividir')
                    #Los que no aparecen en el data que queremos dividir no hay que mirarlos 
                    best_gain[0]=best_gain[0]

            @else_
            def block():
                nada=0
                #Lo ideal seria que saliese del for
                #una especie de break
    
    return best_gain[0], best_question

#----------------------------------- Comprobacion best_split_gini_random -------------------------------------
#ES MEJOR HACERLO CON UN DATASET MAS GRANDE. HAGO LA PRUEBA CON ARBOL DECISION COMPRAS 
#En este caso hay dos variables edad y salario, yo creo que merece la pena que mire las dos porque son muy preprocesamiento
#En cuanto a los valores hay 300, con que mida 10 random en cada  iteracion me vale. 


partition_list_iter0=sfix.Array(len(training_data))
@for_range(len(training_data))
def range_body(i):
    partition_list_iter0[i]=sfix(0)

start_timer(1)
best_gain0, best_question0= best_split_gini_random(training_data,valores_y,partition_list_iter0,nodo=sfix(0),numeric_list=numeric_list,iteration=sfix(0),p=sfix(0),max_features=2,max_values=10,n_variablesX=2)
stop_timer(1)

print_ln('\nLa mayor ganancia de informacion en el nodo 0 es: %s',best_gain0.reveal())

print_ln('\nY se consigue con la pregunta: \n')

@for_range(2)
def range_body(i):
    print_str(' %s',best_question0[i].reveal()) #Para imprimir la pregunta en la misma linea


#....FUNCIONA CORRECTAMENTE...



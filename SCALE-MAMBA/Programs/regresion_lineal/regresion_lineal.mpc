# Normalmente se analiza primero con un grafico de dispersion.
# No se hacer el grafico, pero a ver si consigo deducir algo de los datos.
# El realizar la representación grafica de los datos para demostrar la relacion entre el valor del coeficiente de correlacion y la forma de la grafica es fundamental ya que existen relaciones no lineale

#Ejemplo de: https://empresas.blogthinkbig.com/las-matematicas-del-machine-learning-ejemplos-de-regresion-lineal-ii-y-multilineal/
#indice de mortalidad (Y) y el consumo medio diario de cigarrillos (X)


#····················PRIMERO CORRELACION······················
#1- Representacion grafica entre cada par de variables: nube de puntos
#   Cuanto mas agrupados los puntos mayor relacion habra entre las variables
#   Si la nube de puntos presenta posicion ascendente: correlacion positiva (cuando aumenta una variable aumenta tambien la otra)
#   Si presenta posicion descendente: correlacion negativa
#   Lo que aparece en los graficos no indica que haya una relacion de causa a efecto, habra que demostrarlo mas adelante
#2- Se estima el coeficiente de correlacion de Pearson, r. 
#   Es una medida de dependencia LINEAL
#   Las variables tienen que ser cuantitativas y continuas.
#   Toma valores entre -1 y 1:
#       Si r=1 --> Correlacion positiva perfecta. Dependencia total directa. Cuando una aumenta la otra tambien en proporcion constante.
#       Si 0<r<1 --> Correlacion positiva.
#       Si r=0 --> No existe relacion lineal, pero esto no necesariamente implica que las variables no son independientes.
#                  Pueden existir todavia relaciones no lineales entre las dos variables. 
#       Si -1<r<0 --> Existe una correlacion negativa.
#       Si r=-1 --> Correlacion negativa perfecta. Dependencia total inversa. Cuando una aumenta la otra disminuye en proporcion constante. 
#       Coeficiente igual o superior a +- 0.7 indica una buena correlacion. 
#   Es independiente de la escala de medida de las variables. 
#3- Covarianza depende de la escala de medida de las variables.
#   Indica el grado de variacion conjunta de variables aleatorias respecto a sus medidas. 
#   Dato basico para determinar si existe una dependencia.
#   De la covarianza solo nos dice algo el signo.
#   Magntiud de la relacion lineal: version normalizada de la covarianza --> coeficiente de correlacion
#   >0: dependencia directa(positiva)
#   =0: no existencia de una relacion LINEAL (?) entre las dos variables
#   <0: dependencia inversa(negativa)
#   Si X e Y son independientes --> covarianza es cero 
#   Covarianza es cero -->NO(en general)    X e Y independientes

#   relacion lineal, cuadratica, exponencial, logaritimica ...
#   CUIDADO! CORRELACION NO IMPLICA CAUSALIDAD.
#   Que la relacion entre las variables sea muy fuerte no significa que una de ellas sea la causa de la otra. 
#   Tampoco significa que no lo sea. Puede ser que si o puede ser que exista una variable adicional que hace que se produzca esa correlacion. 
#   A veces que exista una correlacion puede ser pura casualidad. 
#   Tendencia o patron de emparejamiento entre los distintos valores de esas variables, eso si. 





from Compiler import mpc_math
X=sfix.Array(7)
X[0]=sfix(3)
X[1]=sfix(5)
X[2]=sfix(6)
X[3]=sfix(15)
X[4]=sfix(20)
X[5]=sfix(40)
X[6]=sfix(45)


Y=sfix.Array(7)
Y[0]=sfix(0.2)
Y[1]=sfix(0.3)
Y[2]=sfix(0.3)
Y[3]=sfix(0.5)
Y[4]=sfix(0.7)
Y[5]=sfix(1.4)
Y[6]=sfix(1.5)

# Quiero escribir una relacion asi: Y=b_0 +b_1X
n=7

# Media de X
suma1=sfix(0)
for i in range(n):
  suma1 = suma1 + X[i]

print_ln('\nLa suma1: %s',suma1.reveal())
media1=suma1/sfix(n)
print_ln('\nLa media de X: %s\n', media1.reveal())

# Media de Y
suma2=sfix(0)
for i in range(n):
  suma2 = suma2 + Y[i]

media2=suma2/sfix(n)
print_ln('\nLa media de Y: %s\n', media2.reveal())

#Sx: desviacion estandar de la variable X
sumasx=sfix(0)
for i in range(n):
    sumasx=sumasx+(X[i]-media1)**2
sumasx=mpc_math.sqrt(sumasx/sfix(n))
print_ln('\nLa Sx: %s\n', sumasx.reveal())

#Sx: desviacion estandar de la variable Y
sumasy=sfix(0)
for i in range(n):
    sumasy=sumasy+(Y[i]-media2)**2
sumasy=mpc_math.sqrt(sumasy/sfix(n))
print_ln('\nLa Sy: %s\n', sumasy.reveal())

#Sxy: covarianza
sumasxy=sfix(0)
for i in range(n):
    sumasxy=sumasxy+(X[i]-media1)*(Y[i]-media2)
sumasxy=sumasxy/sfix(n)
print_ln('\nLa Sxy: %s\n', sumasxy.reveal())
#Si la covarianza es positiva las dos variables tienen una relacion directa. Cuando una crece la otra tambien.
#Si la covarianza es negativa las dos variables tienen una relacion inversa. Cuando una crece la otra decrece.

#SI SABEMOS QUE LA RELACION ES LINEAL:
#beta1
beta1=sumasxy/(sumasx**2)
print_ln('\nBeta1: %s',beta1.reveal())

#beta0
beta0=media2-beta1*media1
print_ln('\nBeta0: %s',beta0.reveal())

#Coeficiente de correlacion de Pearson. 
r=sumasxy/(sumasx*sumasy)
print_ln('\nCoeficiente de correlacion: %s',r.reveal())

#Es un valor muy próximo a 1, por lo que la dependencia de las variables es muy directa
#A mayor consumo medio diario de cigarrillos diarios, mayor índice de mortalidad.